#include "Lattice.h"
#include <iostream>
#include <cstring>

using namespace std;

//#define COALESCED_MEMORY

// Get the header file
// Generated by setup.py
const string header = {
#include "element.gpuh"
};

Lattice::Lattice(SymplecticIntegrator& integrator,int gpuId) : factory(PassMethodFactory(integrator)) {
  lost = nullptr;
  gpu = AbstractGPU::getInstance()->createContext(gpuId);
}

Lattice::~Lattice() {
  for(auto & element : elements)
    delete element;
  gpu->freeDevice(gpuRing);
  delete gpu;
  delete[] lost;
}

void Lattice::addElement() {

  string passMethod = AbstractInterface::getInstance()->getString("PassMethod");
  AbstractElement *elem = factory.createElement(passMethod);
  elements.push_back(elem);

}

uint32_t Lattice::getNbElement() {
  return elements.size();
}

GPUContext *Lattice::getGPUContext() {
  return gpu;
}

void Lattice::generateGPUKernel() {

  double t0,t1;
  t0=AbstractGPU::get_ticks();

  std::string code;

  code.append(header);
  AbstractGPU::getInstance()->addUtilsFunctions(code);
  factory.generateUtilsFunctions(code);
  factory.generatePassMethods(code);

  // Store particle coordinates in rout
  string routCode;
  routCode.append("    refIdx = refpts[elem];\n");
  routCode.append("    if(refIdx>=0) {\n");
  routCode.append("      _rout[6 * (refIdx*nbPart) +  0] = r6[0];\n");
  routCode.append("      _rout[6 * (refIdx*nbPart) +  1] = r6[1];\n");
  routCode.append("      _rout[6 * (refIdx*nbPart) +  2] = r6[2];\n");
  routCode.append("      _rout[6 * (refIdx*nbPart) +  3] = r6[3];\n");
  routCode.append("      _rout[6 * (refIdx*nbPart) +  4] = r6[4];\n");
  routCode.append("      _rout[6 * (refIdx*nbPart) +  5] = r6[5];\n");
  routCode.append("    }\n");

  // GPU main track function
  // extern C to prevent from mangled name
  code.append("extern \"C\" __global__ void track(ELEMENT* gpuRing,uint32_t startElem,uint32_t nbElement,uint32_t nbTotalElement,\n"
              "                                   uint64_t nbPart,AT_FLOAT* rin,AT_FLOAT* rout,\n"
              "                                   uint32_t* lost,uint64_t turn,\n"
              "                                   int32_t *refpts,uint32_t nbRef\n"
              "                                   ) {\n");

  code.append("  int threadId = blockIdx.x * blockDim.x + threadIdx.x;\n");

#ifdef COALESCED_MEMORY
  // Copy ring param into shared mem (coalesced GM access)
  code.append("  __shared__ ELEMENT elemData[GPU_BLOCK_SIZE];\n");
  code.append("  if( (startElem + threadIdx.x) < nbTotalElement ) {\n");
  code.append("     uint64_t *dPtr = (uint64_t *)&elemData[threadIdx.x];\n");
  code.append("     uint64_t *sPtr = ((uint64_t *)gpuRing) + (startElem + threadIdx.x);\n");
  code.append("     for(int i=0;i<sizeof(ELEMENT)/8;i++) {\n");
  code.append("       dPtr[i] = sPtr[i*nbTotalElement];\n");
  code.append("     }\n");
  code.append("  }\n");
  // Wait that all thread has filled the shared mem
  code.append("  __syncthreads();\n");

  code.append("  ELEMENT* elemPtr = elemData;\n");
  code.append("  AT_FLOAT* _r6 = rin + threadId;\n");
  code.append("  uint64_t r6Stride = nbPart;\n");
#else
  code.append("  ELEMENT* elemPtr = &gpuRing[startElem];\n");
  code.append("  AT_FLOAT* _r6 = rin + (6 * threadId);\n");
  code.append("  uint64_t r6Stride = 1;\n");
#endif

  // Exit if particle lost
  code.append("  if(lost[threadId]) return;\n");

  code.append("  AT_FLOAT* _rout = rout + 6 * ((uint64_t)turn * (uint64_t)nbPart * (uint64_t)nbRef + (uint64_t)(threadId));\n");

  // Copy particle coordinates into registers
  code.append("  AT_FLOAT sr6[6];\n");
  code.append("  sr6[0] = _r6[0*r6Stride];\n"); // x
  code.append("  sr6[1] = _r6[1*r6Stride];\n"); // px/p0 = x'(1+d)
  code.append("  sr6[2] = _r6[2*r6Stride];\n"); // y
  code.append("  sr6[3] = _r6[3*r6Stride];\n"); // py/p0 = y'(1+d)
  code.append("  sr6[4] = _r6[4*r6Stride];\n"); // d = (pz-p0)/p0
  code.append("  sr6[5] = _r6[5*r6Stride];\n"); // c.tau (time lag)
  code.append("  AT_FLOAT* r6 = sr6;\n");

  // Loop over elements
  code.append("  int32_t refIdx = 0;\n");
  code.append("  int elem = startElem;\n");
  code.append("  for(; elem < startElem+nbElement; elem++) {\n");
  code.append(routCode);
  code.append("    switch(elemPtr->Type) {\n");
  factory.generatePassMethodsCalls(code);
  code.append("    }\n");
  code.append("    elemPtr++;\n");
  code.append("  }\n");

  // Copy back particle coordinates to global mem
  code.append("  _r6[0*r6Stride] = sr6[0];\n");
  code.append("  _r6[1*r6Stride] = sr6[1];\n");
  code.append("  _r6[2*r6Stride] = sr6[2];\n");
  code.append("  _r6[3*r6Stride] = sr6[3];\n");
  code.append("  _r6[4*r6Stride] = sr6[4];\n");
  code.append("  _r6[5*r6Stride] = sr6[5];\n");

  code.append("  if( elem==nbTotalElement ) {\n");

  code.append(routCode);

  // Particle lost check
  code.append("    bool pLost = !isfinite(_r6[0]) || !isfinite(_r6[1]) ||\n");
  code.append("                 !isfinite(_r6[2]) || !isfinite(_r6[3]) ||\n");
  code.append("                 !isfinite(_r6[4]) || !isfinite(_r6[5]) ||\n");
  code.append("                 (fabs(_r6[0]) > 1.0 || fabs(_r6[1]) > 1.0) ||\n");
  code.append("                 (fabs(_r6[2]) > 1.0 || fabs(_r6[3]) > 1.0);\n");

  code.append("    if(!lost[threadId] & pLost) {\n");
  code.append("      _r6[0] = NAN;\n");
  code.append("      _r6[1] = 0;\n");
  code.append("      _r6[2] = 0;\n");
  code.append("      _r6[3] = 0;\n");
  code.append("      _r6[4] = 0;\n");
  code.append("      _r6[5] = 0;\n");
  code.append("      lost[threadId] = turn + 1;\n");
  code.append("    }\n");
  code.append("  }\n");
  code.append("}\n");

  t1=AbstractGPU::get_ticks();

  cout << "Code generation: " << (t1-t0)*1000.0 << "ms" << endl;

  t0=AbstractGPU::get_ticks();
  gpu->compile(code);
  t1=AbstractGPU::get_ticks();
  cout << "Code compilation: " << (t1-t0)*1000.0 << "ms" << endl;

  t0=AbstractGPU::get_ticks();
  fillGPUMemory();
  t1=AbstractGPU::get_ticks();
  cout << "GPU lattice loading: " << (t1-t0)*1000.0 << "ms" << endl;

}

void Lattice::fillGPUMemory() {

  // Check ELEMENT structure
  if( sizeof(ELEMENT)%8 != 0 )
    throw string("ELEMENT structure must have a size multiple of 8");

  // Get total memory size
  uint64_t elemSize = elements.size() * sizeof( ELEMENT );
  uint64_t size = elemSize;
  uint64_t privSize = 0;
  for(auto & element : elements)
    privSize += element->getMemorySize();
  size += privSize;

  // Allocate GPU Memory
  gpu->allocDevice(&gpuRing, size);

  // Copy element data
  ELEMENT *memPtr = (ELEMENT *)malloc(size);
  unsigned char *gpuPtr = (unsigned char *)gpuRing + elemSize;
  unsigned char *privPtr = (unsigned char *)memPtr + elemSize;
  ELEMENT *ptr = memPtr;
  for(auto & element : elements) {
    element->fillGPUMemory(ptr, privPtr, gpuPtr);
    ptr++;
    privPtr += element->getMemorySize();
    gpuPtr += element->getMemorySize();
  }

  // Transpose ELEMENT memory for GPU coalescence access
#ifdef COALESCED_MEMORY
  size_t X = sizeof(ELEMENT)/8;
  size_t Y = elements.size();
  Transpose64(X,Y,memPtr);
#endif
  gpu->hostToDevice(gpuRing,memPtr,size);
  free(memPtr);

}

void Lattice::Transpose64(int32_t X,int32_t Y,void *mem) {

  uint64_t *memPtr= (uint64_t *)mem;
  uint64_t *memPtrT64 = (uint64_t *)malloc(X*Y*8);
  for(size_t y=0;y<Y;y++)
    for(size_t x=0;x<X;x++)
      memPtrT64[x*Y + y] = memPtr[x + y*X];
  memcpy(mem,memPtrT64,X*Y*8);
  free(memPtrT64);

}

void Lattice::run(uint64_t nbTurn,uint64_t nbParticles,AT_FLOAT *rin,AT_FLOAT *rout,uint32_t nbRef,uint32_t *refPts) {

  generateGPUKernel();

  double t0 = AbstractGPU::get_ticks();

  // Copy rin to gpu mem
  void *gpuRin;
  gpu->allocDevice(&gpuRin, nbParticles * 6 * sizeof(AT_FLOAT));
#ifdef COALESCED_MEMORY
  Transpose64(6,nbParticles,rin);
#endif
  gpu->hostToDevice(gpuRin, rin, nbParticles * 6 * sizeof(AT_FLOAT));

  // Expand ref indexes
  int32_t *expandedRefPts = new int32_t[elements.size()+1];
  for(int i=0;i<=elements.size();i++)
    expandedRefPts[i] = -1;
  for(int i=0;i<nbRef;i++)
    expandedRefPts[refPts[i]] = (int32_t)i;
  void *gpuRefs;
  gpu->allocDevice(&gpuRefs, (elements.size() + 1) * sizeof(int32_t));
  gpu->hostToDevice(gpuRefs, expandedRefPts, (elements.size() + 1) * sizeof(int32_t));

  // Lost flags
  // Lost dummy particles are created to fill the thread block
  delete[] lost;
  uint32_t dummyParticles = (GPU_BLOCK_SIZE - nbParticles%GPU_BLOCK_SIZE) % GPU_BLOCK_SIZE;
  uint32_t lostSize = (nbParticles + dummyParticles) * sizeof(uint32_t);
  lost = new uint32_t[nbParticles + dummyParticles];
  for(uint32_t i=0;i<nbParticles;i++) lost[i] = 0;
  for(uint32_t i=nbParticles;i<nbParticles+dummyParticles;i++) lost[i] = 1;
  void *gpuLost;
  gpu->allocDevice(&gpuLost, lostSize);
  gpu->hostToDevice(gpuLost, lost, lostSize);

  // rout
  uint64_t routSize = nbParticles * nbRef * nbTurn * 6 * sizeof(AT_FLOAT);
  void *gpuRout;
  gpu->allocDevice(&gpuRout, routSize);

  // Call GPU
  gpu->resetArg();
  uint32_t nbElement = elements.size();
  uint32_t startElem;
  uint32_t nbElemToProcess;
  uint64_t turn;
  gpu->addArg(sizeof(void *),&gpuRing);
  gpu->addArg(sizeof(uint32_t),&startElem);
  gpu->addArg(sizeof(uint32_t),&nbElemToProcess);
  gpu->addArg(sizeof(uint32_t),&nbElement);
  gpu->addArg(sizeof(uint64_t),&nbParticles);
  gpu->addArg(sizeof(void *),&gpuRin);
  gpu->addArg(sizeof(void *),&gpuRout);
  gpu->addArg(sizeof(void *),&gpuLost);
  gpu->addArg(sizeof(uint64_t),&turn);
  gpu->addArg(sizeof(void *),&gpuRefs);
  gpu->addArg(sizeof(uint32_t),&nbRef);


  // Turn loop
#ifdef COALESCED_MEMORY
  uint32_t leftNbElement = nbElement%GPU_BLOCK_SIZE;
  uint32_t alignedNbElem = nbElement - leftNbElement;
  for(turn=0;turn<nbTurn;turn++) {
    // By block of GPU_BLOCK_SIZE elements
    nbElemToProcess = GPU_BLOCK_SIZE;
    for (startElem = 0; startElem < alignedNbElem; startElem += GPU_BLOCK_SIZE)
      gpu->run(GPU_BLOCK_SIZE, nbParticles + dummyParticles);
    // Remaining elements
    nbElemToProcess = leftNbElement;
    if( nbElemToProcess ) gpu->run(GPU_BLOCK_SIZE, nbParticles + dummyParticles);
  }
#else
  for(turn=0;turn<nbTurn;turn++) {
    startElem = 0;
    nbElemToProcess = nbElement;
    gpu->run(GPU_BLOCK_SIZE, nbParticles + dummyParticles);
  }
#endif

  // Get back data
  gpu->deviceToHost(rout,gpuRout,routSize);
  gpu->deviceToHost(lost,gpuLost,lostSize);

  int nbLost = 0;
  for(int i=0;i<nbParticles;i++)
    if(lost[i]) nbLost++;
  cout << "Lost: " << nbLost << endl;

  // Free
  gpu->freeDevice(gpuRin);
  gpu->freeDevice(gpuRout);
  gpu->freeDevice(gpuRefs);
  gpu->freeDevice(gpuLost);
  delete[] expandedRefPts;

  double t1 = AbstractGPU::get_ticks();
  cout << "GPU tracking: " << (t1-t0)*1000.0 << "ms" << endl;

}
