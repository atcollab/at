#include "Lattice.h"
#include <iostream>

using namespace std;

// Get the header file
// Generated by setup.py
const string header = {
#include "element.gpuh"
};

Lattice::Lattice(SymplecticIntegrator& integrator,int gpuId) : factory(PassMethodFactory(integrator)) {
  lost = nullptr;
  gpu = AbstractGPU::getInstance()->createContext(gpuId);
}

Lattice::~Lattice() {
  for(auto & element : elements)
    delete element;
  gpu->freeDevice(gpuRing);
  delete gpu;
  delete[] lost;
}

void Lattice::addElement() {

  string passMethod = AbstractInterface::getInstance()->getString("PassMethod");
  AbstractElement *elem = factory.createElement(passMethod);
  elements.push_back(elem);

}


void Lattice::generateGPUKernel(std::string& code,bool doRout) {

  double t0,t1;
  t0=AbstractGPU::get_ticks();

  code.append(header);
  AbstractGPU::getInstance()->addUtilsFunctions(code);
  factory.generateUtilsFunctions(code);
  factory.generatePassMethods(code);

  // Store particle coordinates in rout
  string routCode;
  routCode.append("    refIdx = refpts[elem];\n");
  routCode.append("    if(refIdx>=0) {\n");
  routCode.append("      _rout[6 * (refIdx*nbPart) +  0] = r6[0];\n");
  routCode.append("      _rout[6 * (refIdx*nbPart) +  1] = r6[1];\n");
  routCode.append("      _rout[6 * (refIdx*nbPart) +  2] = r6[2];\n");
  routCode.append("      _rout[6 * (refIdx*nbPart) +  3] = r6[3];\n");
  routCode.append("      _rout[6 * (refIdx*nbPart) +  4] = r6[4];\n");
  routCode.append("      _rout[6 * (refIdx*nbPart) +  5] = r6[5];\n");
  routCode.append("    }\n");

  // GPU main track function
  code.append("__global__ void track(ELEMENT* gpuRing,uint32_t nbElement,uint64_t nbPart,AT_FLOAT* rin,AT_FLOAT* rout,\n"
              "                      uint32_t* lost,uint64_t turn,uint32_t *refpts,uint32_t nbRef) {\n");
  code.append("  int threadId = blockIdx.x * blockDim.x + threadIdx.x;\n");
  code.append("  AT_FLOAT* _r6 = rin + (6 * threadId);\n");
  code.append("  AT_FLOAT* _rout = rout + 6 * ((uint64_t)turn * (uint64_t)nbPart * (uint64_t)nbRef + (uint64_t)(threadId));\n");

  // Copy particle coordinates into fast shared mem
  code.append("  __shared__ AT_FLOAT sr6[GPU_GRID * 6];\n");
  code.append("  sr6[0 + threadIdx.x * 6] = _r6[0];\n"); // x
  code.append("  sr6[1 + threadIdx.x * 6] = _r6[1];\n"); // px/p0 = x'(1+d)
  code.append("  sr6[2 + threadIdx.x * 6] = _r6[2];\n"); // y
  code.append("  sr6[3 + threadIdx.x * 6] = _r6[3];\n"); // py/p0 = y'(1+d)
  code.append("  sr6[4 + threadIdx.x * 6] = _r6[4];\n"); // d = (pz-p0)/p0
  code.append("  sr6[5 + threadIdx.x * 6] = _r6[5];\n"); // c.tau (time lag)
  code.append("  AT_FLOAT* r6 = &sr6[0 + threadIdx.x * 6];\n");

  // Loop over elements
  code.append("  ELEMENT* elemPtr = gpuRing;\n");
  code.append("  uint32_t rCount = 0;\n");
  code.append("  uint32_t refIdx = 0;\n");
  code.append("  uint32_t elem = 0;\n");
  code.append("  for(elem = 0; elem < nbElement; elem++) {\n");
  if(doRout) code.append(routCode);
  code.append("    switch(elemPtr->Type) {\n");
  factory.generatePassMethodsCalls(code);
  code.append("    }\n");
  code.append("    elemPtr++;\n");
  code.append("  }\n");
  if(doRout) code.append(routCode);

  // Copy back particle coordinate to global mem
  code.append("  _r6[0] = sr6[0 + threadIdx.x * 6];\n");
  code.append("  _r6[1] = sr6[1 + threadIdx.x * 6];\n");
  code.append("  _r6[2] = sr6[2 + threadIdx.x * 6];\n");
  code.append("  _r6[3] = sr6[3 + threadIdx.x * 6];\n");
  code.append("  _r6[4] = sr6[4 + threadIdx.x * 6];\n");
  code.append("  _r6[5] = sr6[5 + threadIdx.x * 6];\n");

  // Particle lost check
  code.append("  bool pLost = !isfinite(_r6[0]) ||\n");
  code.append("               !isfinite(_r6[1]) ||\n");
  code.append("               !isfinite(_r6[2]) ||\n");
  code.append("               !isfinite(_r6[3]) ||\n");
  code.append("               !isfinite(_r6[4]) ||\n");
  code.append("               !isfinite(_r6[5]) ||\n");
  code.append("               (fabs(_r6[0]) > 1.0 || fabs(_r6[1]) > 1.0) ||\n");
  code.append("               (fabs(_r6[2]) > 1.0 || fabs(_r6[3]) > 1.0);\n");

  code.append("  if(!lost[threadId] & pLost) {\n");
  code.append("    _r6[0] = NAN;\n");
  code.append("    _r6[1] = 0;\n");
  code.append("    _r6[2] = 0;\n");
  code.append("    _r6[3] = 0;\n");
  code.append("    _r6[4] = 0;\n");
  code.append("    _r6[5] = 0;\n");
  code.append("    lost[threadId] = turn + 1;\n");
  code.append("  }\n");

  code.append("}\n");

  t1=AbstractGPU::get_ticks();

  cout << "Code generation: " << (t1-t0)*1000.0 << "ms" << endl;

  t0=AbstractGPU::get_ticks();
  gpu->compile(code);
  t1=AbstractGPU::get_ticks();
  cout << "Code compilation: " << (t1-t0)*1000.0 << "ms" << endl;

  t0=AbstractGPU::get_ticks();
  fillGPUMemory();
  t1=AbstractGPU::get_ticks();
  cout << "GPU lattive loading: " << (t1-t0)*1000.0 << "ms" << endl;

}

void Lattice::fillGPUMemory() {

  // Get total memory size
  uint64_t elemSize = elements.size() * sizeof( ELEMENT );
  uint64_t size = elemSize;
  for(auto & element : elements)
    size += element->getMemorySize();

  // Allocate
  gpu->allocDevice(&gpuRing, size, false);

  // Copy element data
  unsigned char *memPtr = (unsigned char *)gpuRing;
  unsigned char *privPtr = (unsigned char *)gpuRing + elemSize;
  for(auto & element : elements) {
    element->fillGPUMemory(gpu, memPtr, privPtr);
    memPtr += sizeof( ELEMENT );
    privPtr += element->getMemorySize();
  }

}

void Lattice::run(uint64_t nbTurn,uint64_t nbParticles,AT_FLOAT *rin,AT_FLOAT *rout,uint32_t nbRef,uint32_t *refPts) {

  // Copy rin to gpu mem
  void *gpuRin;
  gpu->allocDevice(&gpuRin, nbParticles * 6 * sizeof(AT_FLOAT), false);
  gpu->hostToDevice(gpuRin, rin, nbParticles * 6 * sizeof(AT_FLOAT));

  // Expanded ref index
  int32_t expandedRefPts[elements.size()+1];
  for(int i=0;i<elements.size();i++)
    expandedRefPts[i] = -1;
  for(int i=0;i<nbRef;i++)
    expandedRefPts[refPts[i]] = (int32_t)refPts[i];
  void *gpuRefs;
  gpu->allocDevice(&gpuRefs, (elements.size() + 1) * sizeof(int32_t),false);
  gpu->hostToDevice(gpuRefs, expandedRefPts, (elements.size() + 1) * sizeof(int32_t));

  // Lost flags
  delete[] lost;
  uint32_t lostSize = nbParticles * sizeof(uint32_t);
  lost = new uint32_t[nbParticles];
  void *gpuLost;
  gpu->allocDevice(&gpuLost, lostSize, true);

  // rout
  uint64_t routSize = nbParticles * nbRef * nbTurn * 6;
  void *gpuRout;
  gpu->allocDevice(&gpuRout, routSize, false);

  // Call GPU
  gpu->resetArg();
  uint32_t nbElement = elements.size();
  uint64_t turn;
  gpu->addArg(sizeof(void *),&gpuRing);
  gpu->addArg(sizeof(uint32_t),&nbElement);
  gpu->addArg(sizeof(uint64_t),&nbParticles);
  gpu->addArg(sizeof(void *),&gpuRin);
  gpu->addArg(sizeof(void *),&gpuRout);
  gpu->addArg(sizeof(void *),&gpuLost);
  gpu->addArg(sizeof(uint64_t),&turn);
  gpu->addArg(sizeof(void *),&gpuRefs);
  gpu->addArg(sizeof(uint32_t),&nbRef);

  // Turn loop
  for(turn=0;turn<nbTurn;turn++)
    // One particle per thread
    gpu->run(GPU_GRID,nbParticles);

  // Get back data
  gpu->deviceToHost(rout,gpuRout,routSize);
  gpu->deviceToHost(lost,gpuLost,lostSize);

  // Free
  gpu->freeDevice(gpuRin);
  gpu->freeDevice(gpuRout);
  gpu->freeDevice(gpuRefs);
  gpu->freeDevice(gpuLost);

}
